<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Georgios Douzas">
<meta name="author" content="Fernando Bacao">
<meta name="keywords" content="Machine Learning Classification, Imbalanced Learning, Oversampling, Clustering, Geometric SMOTE, Scikit-Learn">

<title>imbalanced-learn-extra: A Python package for novel oversampling algorithms – Georgios Douzas</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-79108a0fc1995748cbd19a5b0e3e3e7c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Georgios Douzas</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/georgedouzas"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/gdouzas"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">imbalanced-learn-extra: A Python package for novel oversampling algorithms</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Artificial Intelligence</div>
    <div class="quarto-category">Machine Learning</div>
    <div class="quarto-category">Imbalanced Data</div>
    <div class="quarto-category">Publication</div>
  </div>
  </div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Authors</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Georgios Douzas </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            NOVA IMS
          </p>
      </div>
    <div class="quarto-title-meta-contents">
    <p class="author">Fernando Bacao </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            NOVA IMS
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    <p>Learning from imbalanced data is a common and challenging problem in supervised learning, as standard classifiers are typically designed for balanced class distributions. Among various strategies to address this issue, oversampling algorithms, which generate artificial data to balance class distributions, offer greater flexibility than modifying classification algorithms. In this paper, we present the <code>imbalanced-learn-extra</code> library, describe its implementation in detail, and make it freely available to the machine learning community. The library integrates seamlessly with the Scikit-Learn ecosystem, enabling researchers and practitioners to incorporate it into their existing workflows with ease. The <code>imbalanced-learn-extra</code> Python library implements novel oversampling methods to tackle both between-class and within-class imbalances. Specifically, Geometric SMOTE, enhances the traditional SMOTE algorithm by expanding the data generation area beyond the line segments connecting minority class instances, allowing for greater diversity in synthetic samples and effectively addressing between-class imbalances. On the other hand leverages a clustering-based oversampling addresses within-class imbalances by partitioning the input space into clusters and applying oversampling within each cluster using appropriate resampling ratios. These methods have demonstrated superior performance compared to standard oversampling techniques across a variety of datasets.</p>
  </div>
</div>

<div>
  <div class="keywords">
    <div class="block-title">Keywords</div>
    <p>Machine Learning Classification, Imbalanced Learning, Oversampling, Clustering, Geometric SMOTE, Scikit-Learn</p>
  </div>
</div>

</header>


<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The imbalanced learning problem describes the case wherein a machine learning classification task, using datasets with binary or multi-class targets, one of the classes, called the majority class, has a significantly higher number of samples compared to the remaining classes, called the minority class(es) <span class="citation" data-cites="goos_smoteboost_2003">(<a href="#ref-goos_smoteboost_2003" role="doc-biblioref">Nitesh V. Chawla et al. 2003</a>)</span>. Learning from imbalanced data is a non-trivial problem for both academic researchers and industry practitioners that can be frequently found in multiple domains such as chemical and biochemical engineering, financial management, information technology, security, business, agriculture or emergency management <span class="citation" data-cites="haixiang_learning_2017">(<a href="#ref-haixiang_learning_2017" role="doc-biblioref">Haixiang et al. 2017</a>)</span>.</p>
<p>A bias towards the majority class is induced when imbalanced data are used to train standard machine learning algorithms. This results in low classification accuracy, especially for the minority class(es), when the classifier is evaluated on unseen data. An important measure for the degree of data imbalance is the Imbalance Ratio (<span class="math inline">\(IR\)</span>), defined as the ratio between the number of samples of the majority class and each of the minority classes. Using a rare disease detection task as an example, with 1% of positive cases corresponding to an <span class="math inline">\(IR=\frac{0.99}{0.01}=99\)</span>, a trivial classifier that always labels a person as healthy will score a classification accuracy of 99%. However, in this case, all positive cases remain undetected. The observed values of <span class="math inline">\(IR\)</span> are often between 100 and 100.000 <span class="citation" data-cites="chawla_smote_2002">(<a href="#ref-chawla_smote_2002" role="doc-biblioref">N. V. Chawla et al. 2002</a>)</span>, <span class="citation" data-cites="barua_mwmote_2014">(<a href="#ref-barua_mwmote_2014" role="doc-biblioref">Barua et al. 2014</a>)</span>. <a href="#fig-imbalanced-problem" class="quarto-xref">Figure&nbsp;1</a> presents an example of imbalanced data in two dimensions as well as the decision boundary identified by a typical classifier that uses them as training data.</p>
<div id="fig-imbalanced-problem" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-imbalanced-problem-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="imbalanced_problem.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-imbalanced-problem-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Imbalanced data in two dimensions. The decision boundary of a typical classifier shows a bias towards the majority class.
</figcaption>
</figure>
</div>
<p>In this paper, we present <code>imbalanced-learn-extra</code>, a Python library that implements novel oversampling algorithms, including clustering-based oversampling and Geometric SMOTE. The clustering-based approach allows for any combination of a <a href="https://scikit-learn.org/stable/">Scikit-Learn</a> <span class="citation" data-cites="pedregosa_scikit-learn_2012">(<a href="#ref-pedregosa_scikit-learn_2012" role="doc-biblioref">Pedregosa et al. 2012</a>)</span> compatible clustering algorithm and an <a href="https://imbalanced-learn.org/stable/">Imbalanced-Learn</a> <span class="citation" data-cites="lemaitre_imbalanced-learn_2016">(<a href="#ref-lemaitre_imbalanced-learn_2016" role="doc-biblioref">Lemaitre, Nogueira, and Aridas 2016</a>)</span> compatible oversampler. This approach identifies clusters within the input space and applies oversampling individually to each cluster. Additonally, Geometric SMOTE serves as a direct replacement for SMOTE, expanding the data generation mechanism to provide greater flexibility and improved performance.</p>
<p>In <a href="#theoretical-background">Theoretical background</a> section various concepts related to oversampling are presented, while in <a href="#implementation-and-architecture">Implementation and architecture</a> section a description of the software’s implementation and architecture is presented.</p>
</section>
<section id="theoretical-background" class="level1">
<h1>Theoretical background</h1>
<p>Various approaches have been proposed to improve classification results when the training data are imbalanced, a case also known as a between-class imbalance. The most general approach, called oversampling, is the generation of artificial data for the minority class(es) <span class="citation" data-cites="fernandez_analysing_2013">(<a href="#ref-fernandez_analysing_2013" role="doc-biblioref">Fernández et al. 2013</a>)</span>. The synthetic Minority Oversampling Technique (SMOTE) <span class="citation" data-cites="chawla_smote_2002">(<a href="#ref-chawla_smote_2002" role="doc-biblioref">N. V. Chawla et al. 2002</a>)</span> was the first non-trivial oversampler proposed and remains the most popular one. Although SMOTE is effective for generating artificial data, it also has some drawbacks <span class="citation" data-cites="haibo_he_learning_2009">(<a href="#ref-haibo_he_learning_2009" role="doc-biblioref">Haibo He and Garcia 2009</a>)</span>. To improve the quality of the artificial data many variants of SMOTE have been proposed. Nevertheless, they utilize the SMOTE data generation mechanism, which consists of a linear interpolation between minority class samples to generate synthetic instances as shown in figure <a href="#fig-smote" class="quarto-xref">Figure&nbsp;2</a>.</p>
<div id="fig-smote" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-smote-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="smote.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-smote-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Visual representation of the SMOTE data generation mechanism.
</figcaption>
</figure>
</div>
<section id="geometric-smote" class="level2">
<h2 class="anchored" data-anchor-id="geometric-smote">Geometric SMOTE</h2>
<p>The Geometric SMOTE (G-SMOTE) oversampling algorithm <span class="citation" data-cites="douzas_geometric_2019">(<a href="#ref-douzas_geometric_2019" role="doc-biblioref">Douzas and Bacao 2019</a>)</span> uses a different approach compared to existing SMOTE’s variations. More specifically, G-SMOTE oversampling algorithm substitutes the data generation mechanism of SMOTE by defining a flexible geometric region around each minority class instance and generating synthetic instances inside the boundaries of this region. The algorithm requires the selection of the hyperparameters <code>truncation_factor</code> , <code>deformation_factor</code>, <code>selection_strategy</code> and <code>k_neighbors</code>. The first three of them, called geometric hyperparameters, control the shape of the geometric region while the later adjusts its size. Figure <a href="#fig-smote-vs-gsmote" class="quarto-xref">Figure&nbsp;3</a> presents a visual comparison between the data generation mechanisms of SMOTE and G-SMOTE.</p>
<div id="fig-smote-vs-gsmote" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-smote-vs-gsmote-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="smote_vs_gsmote.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-smote-vs-gsmote-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Comparison between the data generation mechanisms of SMOTE and G-SMOTE. SMOTE uses linear interpolation, while G-SMOTE defines a circle as the permissible data generation area.
</figcaption>
</figure>
</div>
</section>
<section id="clustering-based-oversampling" class="level2">
<h2 class="anchored" data-anchor-id="clustering-based-oversampling">Clustering-based oversampling</h2>
<p>In addition to between-class imbalance, within-class imbalance refers to the case where areas of sparse and dense minority class instances exist. As the first step of generating synthetic samples, the SMOTE data generation mechanism selects randomly, with uniform probability, minority class instances. Consequently, dense minority class areas have a high probability of being inflated further, while sparsely populated are likely to remain sparse. This allows for combating between-class imbalance, while the issue of within-class imbalance is ignored <span class="citation" data-cites="hutchison_learning_2004">(<a href="#ref-hutchison_learning_2004" role="doc-biblioref">Prati, Batista, and Monard 2004</a>)</span>.</p>
<p>On the other hand, clustering-based oversampling, as presented in <span class="citation" data-cites="douzas_self-organizing_2017">(<a href="#ref-douzas_self-organizing_2017" role="doc-biblioref">Douzas and Bacao 2017</a>)</span> and <span class="citation" data-cites="douzas_improving_2018">(<a href="#ref-douzas_improving_2018" role="doc-biblioref">Douzas, Bacao, and Last 2018</a>)</span>, aims to deal with both between-class and within-class imbalance problems. Initially, a clustering algorithm is applied to the input space. The resulting clusters allow the identification of sparse and dense minority class(es) areas. A small IR, relative to a threshold, of a particular cluster, is used as an indicator that it can be safely selected as a data generation area, i.e.&nbsp;noise generation is avoided. Furthermore, sparse minority clusters are assigned more synthetic samples, which alleviates within-class imbalance.</p>
<p>Specific realizations of the above approach are SOMO <span class="citation" data-cites="douzas_self-organizing_2017">(<a href="#ref-douzas_self-organizing_2017" role="doc-biblioref">Douzas and Bacao 2017</a>)</span>, KMeans-SMOTE <span class="citation" data-cites="douzas_improving_2018">(<a href="#ref-douzas_improving_2018" role="doc-biblioref">Douzas, Bacao, and Last 2018</a>)</span> and G-SOMO <span class="citation" data-cites="douzas_gsomo_2021">(<a href="#ref-douzas_gsomo_2021" role="doc-biblioref">Douzas, Rauch, and Bacao 2021</a>)</span> algorithms. Empirical studies have shown that the three algorithms outperform SMOTE and its variants across multiple imbalanced datasets, classifiers and evaluation metrics.</p>
</section>
</section>
<section id="implementation-and-architecture" class="level1">
<h1>Implementation and architecture</h1>
<p>A Python implementation of SMOTE and several of its variants is available in the <a href="https://imbalanced-learn.org/stable/">Imbalanced-Learn</a> library <span class="citation" data-cites="lemaitre_imbalanced-learn_2016">(<a href="#ref-lemaitre_imbalanced-learn_2016" role="doc-biblioref">Lemaitre, Nogueira, and Aridas 2016</a>)</span>, which is fully compatible with the popular machine learning toolbox <a href="https://scikit-learn.org/stable/">Scikit-Learn</a> <span class="citation" data-cites="pedregosa_scikit-learn_2012">(<a href="#ref-pedregosa_scikit-learn_2012" role="doc-biblioref">Pedregosa et al. 2012</a>)</span>. In this paper, we present <code>imbalanced-learn-extra</code>. The <code>imbalanced-learn-extra</code> software project is compatible with Python 3.10 or greater. It contains an object-oriented implementation of G-SMOTE and the clustering-based oversampling procedure, as well as detailed <a href="https://https://georgedouzas.github.io/imbalanced-learn-extra/">online documentation</a>. The implementation provides an API that is compatible with Imbalanced-Learn and Scikit-Learn libraries. Therefore, standard machine learning functionalities are supported. The <code>imbalanced-learn-extra</code> project contains the Python package <code>imblearn_extra</code> with the main modules <code>gsmote</code> and <code>clover</code>.</p>
<section id="geometric-smote-1" class="level2">
<h2 class="anchored" data-anchor-id="geometric-smote-1">Geometric SMOTE</h2>
<p>The <code>imblearn_extra/gsmote</code> directory contains the file <code>geometric_smote.py</code> that includes the class <code>GeometricSMOTE</code>, an implementation of the G-SMOTE algorithm. The initialization of a <code>GeometricSMOTE</code> instance requires the selection of G-SMOTE’s hyperparameters that control the generation of synthetic data. Additionally, <code>GeometricSMOTE</code> inherits from the <code>BaseOverSampler</code> class of Imbalanced-Learn library. Therefore, an instance of <code>GeometricSMOTE</code> class provides the <code>fit</code> and <code>fit_resample</code> methods, the two main methods for resampling. This is achieved by implementing the <code>_fit_resample</code> abstract method of the parent class <code>BaseOverSampler</code>. More specifically, the function <code>_make_geometric_sample</code> implements the data generation mechanism of G-SMOTE. This function is called in the <code>_make_geometric_samples</code> method of the <code>GeometricSMOTE</code> class in order to generate the appropriate number of synthetic data for a particular minority class. Finally, the method <code>_make_geometric_samples</code> is called in <code>_fit_resample</code> method to generate synthetic data for all minority classes. Figure #fig-class_diagram provides a visual representation of the above classes and functions hierarchy.</p>
<div id="fig-class-diagram" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="gsmote_class_diagram.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: UML class diagrams and callgraphs of main classes and methods.
</figcaption>
</figure>
</div>
</section>
<section id="clustering-based-oversampling-1" class="level2">
<h2 class="anchored" data-anchor-id="clustering-based-oversampling-1">Clustering-based oversampling</h2>
<p>The <code>imblearn_extra/clover</code> directory contains the <code>distribution</code> and <code>over_sampling</code> directories. The <code>imblearn_extra.clover.distribution</code> module implements the functionality related to the distribution of the generated samples to the identified clusters, while <code>imblearn_extra.clover.over_sampling</code> implements the functionality related to the generation of artificial samples. Both of them are presented in detail below.</p>
<section id="distribution" class="level3">
<h3 class="anchored" data-anchor-id="distribution">Distribution</h3>
<p>The <code>imblearn_extra/clover/distribution</code> directory contains the files <code>base.py</code> and <code>_density.py</code>. The former provides the implementation of the <code>BaseDistributor</code> class, the base class for distributors, while the latter includes the <code>DensityDistributor</code> class, a generalization of the density-based distributor presented in <span class="citation" data-cites="douzas_self-organizing_2017">(<a href="#ref-douzas_self-organizing_2017" role="doc-biblioref">Douzas and Bacao 2017</a>)</span> and <span class="citation" data-cites="douzas_improving_2018">(<a href="#ref-douzas_improving_2018" role="doc-biblioref">Douzas, Bacao, and Last 2018</a>)</span>, that inherits from <code>BaseDistributor</code>. Following the Scikit-Learn API, <code>BaseDistributor</code> includes the public method <code>fit</code>. Also the <code>fit_distribute</code> method is also implemented as the main method of the class.</p>
<p>The <code>fit_distribute</code> method calls the <code>fit</code> method and returns two Python dictionaries that describe the distribution of generated samples inside each cluster and between clusters, respectively. Specifically, the <code>fit</code> method calculates various statistics related to the distribution process, while it calls the <code>_fit</code> method to calculate the actual intra-cluster and inter-cluster distributions. This is achieved by invoking the <code>_intra_distribute</code> and <code>_inter_distribute</code> methods. The <code>BaseDistributor</code> class provides a trivial implementation of them, that should be overwritten when a realization of a distributor class is considered. Therefore, <code>DensityDistributor</code> overwrites both methods as well as the <code>_fit</code> method. The later calls the methods <code>_identify_filtered_clusters</code> and <code>_calculate_clusters_density</code> that identify the clusters used for data generation and calculate their density, respectively. <a href="#fig-distributor-class-diagram" class="quarto-xref">Figure&nbsp;5</a> shows a visual representation of the above classes and functions hierarchy.</p>
<div id="fig-distributor-class-diagram" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-distributor-class-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="distributor_class_diagram.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-distributor-class-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: UML BaseDistributor and DensityDistributor class diagrams and callgraphs of main classes and methods.
</figcaption>
</figure>
</div>
</section>
<section id="oversampling" class="level3">
<h3 class="anchored" data-anchor-id="oversampling">Oversampling</h3>
<p>The <code>imblearn_extra/clover/over_sampling</code> directory contains the files <code>_cluster.py</code>, <code>_kmeans_smote.py</code>, <code>_somo.py</code> and <code>_gsomo.py</code>. The former provides the <code>ClusterOverSampler</code> class, an extension of the Imbalanced-Learn’s <code>BaseOverSampler</code> class, and implements the functionality required by clustering-based oversampling. The rest of the files <code>_kmeans_smote.py</code>, <code>_somo.py</code> and <code>_gsomo.py</code> utilize the <code>ClusterOverSampler</code> class to provide implementations of KMeans SMOTE, SOMO and Geometric SOMO algorithms, respectively. The initializer of <code>ClusterOverSampler</code>, compared to the base class of oversamplers that is implemented in Imbalanced-Learn <code>BaseOverSampler</code>, includes the extra parameters <code>clusterer</code> and <code>distributor</code> and inherits from it. Also following the Imbalanced-Learn API, <code>ClusterOverSampler</code> includes the public methods <code>fit</code> and <code>fit_resample</code>.</p>
<p>The <code>fit</code> method calculates various statistics related to the resampling process, while the <code>fit_resample</code> method returns an enhanced version of the input data by appending the artificially generated samples. Specifically, <code>fit_resample</code> calls the <code>_fit_resample</code> method that in turn calls the <code>_intra_sample</code> and <code>_inter_sample</code> methods to generate the intra-cluster and inter-cluster artificial samples, respectively. This is achieved by invoking the <code>_fit_resample_cluster</code> method that implements the data generation mechanism. Therefore every oversampler that inherits from the <code>ClusterOverSampler</code> class should overwrite <code>_fit_resample_cluster</code>, providing a concrete implementation of the oversampling process. <a href="#fig-oversampler-class-diagram" class="quarto-xref">Figure&nbsp;6</a> shows a visual representation of the above classes and functions hierarchy.</p>
<div id="fig-oversampler-class-diagram" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-oversampler-class-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="oversampler_class_diagram.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-oversampler-class-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: UML BaseOverSampler and BaseClusterOversampler class diagrams and callgraphs of main classes and methods.
</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="software-functionalities" class="level1">
<h1>Software functionalities</h1>
<section id="geometric-smote-2" class="level2">
<h2 class="anchored" data-anchor-id="geometric-smote-2">Geometric SMOTE</h2>
<p>As it was mentioned in subsection, the class <code>GeometricSMOTE</code> represents the G-SMOTE oversampler. The intializer of <code>GeometricSMOTE</code> includes the following G-SMOTE’s hyperparameters: <code>truncation_factor</code>, <code>deformation_factor</code>, <code>selection_strategy</code> and <code>k_neighbors</code> as explained in subsection. Once the <code>GeometricSMOTE</code> object is initialized with a specific parametrization, it can be used to resample the imbalanced data represented by the input matrix <code>X</code> and the target labels <code>y</code>. Following the Scikit-Learn API, both <code>X</code>, <code>y</code> are array-like objects of appropriate shape.</p>
<p>Resampling is achieved by using the two main methods of <code>fit</code> and <code>fit_resample</code> of the <code>GeometricSMOTE</code> object. More specifically, both of them take as input parameters the <code>X</code> and <code>y</code>. The first method computes various statistics which are used to resample <code>X</code> while the second method does the same but additionally returns a resampled version of <code>X</code> and <code>y</code>.</p>
</section>
<section id="clustering-based-oversampling-2" class="level2">
<h2 class="anchored" data-anchor-id="clustering-based-oversampling-2">Clustering-based oversampling</h2>
<p>As it was mentioned in section <a href="#theoretical-background">Theoretical background</a>, clustering-based oversampling initially applies a clustering algorithm to the input space before oversampling is applied to each cluster. This is achieved through the implementation of the <code>ClusterOverSampler</code> class, an extension of Imbalanced-Learn’s <code>BaseOverSampler</code> class. Oversamplers that inherit from <code>ClusterOverSampler</code>, compared to oversamplers inheriting from <code>BaseOverSampler</code>, require two additional initialization parameters: <code>clusterer</code> and <code>distributor</code>. Their default values are for both parameters equal to <code>None</code>, a case that corresponds to the usual oversampling procedure i.e.&nbsp;no clustering applied to the input space. On the other hand if the parameter <code>clusterer</code> is equal to any Scikit-Learn compatible clustering algorithm then clustering of the input space is initially applied, followed by oversampling in each cluster with the distribution of generated samples calculated by the <code>distributor</code> parameter. The default <code>distributor</code> value is an instance of <code>DensityDistributor</code> class as described in subsection <a href="#distribution">Distribution</a>.</p>
<p>The initializer of <code>DensityDistributor</code> includes the following parameters: <code>filtering_threshold</code>, <code>distances_exponent</code>, <code>sparsity_based</code> and <code>distribution_factor</code>. The first parameter is used to identify the filtered clusters, i.e.&nbsp;clusters of samples that are included in the data generation process. The second parameter modifies the density calculation of the filtered clusters by increasing the effect of euclidean distances between samples. The third parameter selects whether generated samples are assigned to filtered clusters inversely proportional to their density. Finally, the last parameter adjusts the intra-cluster to the inter-cluster proportion of generated samples, while it applies only to clusterers that support a neighborhood structure. Once the <code>DensityDistributor</code> object is initialized with a specific parametrization, it can be used to distribute the generated samples to the clusters identified by any clustering algorithm.</p>
<p>Resampling is achieved by using the two main methods of <code>fit</code> and <code>fit_resample</code> of any oversampler inheriting from <code>ClusterOverSampler</code>. More specifically, both of them take as input parameters the input matrix <code>X</code> and target labels <code>y</code>. Following the Scikit-Learn API, both <code>X</code>, <code>y</code> are array-like objects of appropriate shape. The first method computes various statistics which are used to resample <code>X</code>, while the second method does the same but additionally returns a resampled version of <code>X</code> and <code>y</code>.</p>
</section>
<section id="integration" class="level2">
<h2 class="anchored" data-anchor-id="integration">Integration</h2>
<p>The <code>imbalanced-learn-extra</code> project has been designed to integrate with the Imbalanced-Learn toolbox and Scikit-Learn ecosystem. Therefore the <code>GeometricSMOTE</code> and <code>ClusterOverSampler</code> objects can be used in machine learning pipelines, through Imbalanced-Learn’s class <code>Pipeline</code>, that automatically combines <code>samplers</code>, <code>transformers</code> and <code>estimators</code>. The next section provides examples of the above functionalities.</p>
</section>
</section>
<section id="usage-examples" class="level1">
<h1>Usage examples</h1>
<p>Examples of <code>imbalanced-learn-extra</code> usage are given below including basic examples and machine learning pipelines.</p>
<section id="geometric-smote-3" class="level2">
<h2 class="anchored" data-anchor-id="geometric-smote-3">Geometric SMOTE</h2>
<section id="basic-example" class="level3">
<h3 class="anchored" data-anchor-id="basic-example">Basic example</h3>
<p>An example of resampling multi-class imbalanced data using the <code>fit_resample</code> method is presented in the next listing. Initially, a 3-class imbalanced dataset is generated. Next, <code>GeometricSMOTE</code> object is initialized with default values for the hyperparameters, i.e.&nbsp;<code>truncation_factor=1.0</code>, <code>deformation_factor=0.0</code>, <code>selection_strategy='combined'</code>. Finally, the object’s <code>fit_resample</code> method is used to resample the data. Printing the class distribution before and after resampling confirms that the resampled data <code>X_res</code>, <code>y_res</code> are perfectly balanced. <code>X_res</code>, <code>y_res</code> can be used as training data for any classifier in the place of <code>X</code>, <code>y</code>.</p>
<div id="1fd8df4c" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import classes and functions.</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn_extra.gsmote <span class="im">import</span> GeometricSMOTE</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate an imbalanced 3-class dataset.</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  random_state<span class="op">=</span><span class="dv">23</span>, </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  n_classes<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  n_informative<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  n_samples<span class="op">=</span><span class="dv">500</span>, </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  weights<span class="op">=</span>[<span class="fl">0.8</span>, <span class="fl">0.15</span>, <span class="fl">0.05</span>]</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a GeometricSMOTE object with default hyperparameters.</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>gsmote <span class="op">=</span> GeometricSMOTE(random_state<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Resample the imbalanced dataset.</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>X_res, y_res <span class="op">=</span> gsmote.fit_resample(X, y)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Print number of samples per class for initial and resampled data.</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>init_count <span class="op">=</span> <span class="bu">list</span>(Counter(y).values()) </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>resampled_count <span class="op">=</span> <span class="bu">list</span>(Counter(y_res).values())</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Initial class distribution: </span><span class="sc">{</span>init_count<span class="sc">}</span><span class="ss">.'</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Resampled class distribution: </span><span class="sc">{</span>resampled_count<span class="sc">}</span><span class="ss">.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Initial class distribution: [400, 75, 25].
Resampled class distribution: [400, 400, 400].</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/gdouzas/Library/Application Support/pdm/venvs/blog-h-aHQONM-3.11/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.
  warnings.warn(</code></pre>
</div>
</div>
</section>
<section id="machine-learning-pipeline" class="level3">
<h3 class="anchored" data-anchor-id="machine-learning-pipeline">Machine learning pipeline</h3>
<p>As mentioned before, the <code>GeometricSMOTE</code> object can be used as a part of a machine learning pipeline. The next listing presents a pipeline composed by a G-SMOTE oversampler, a PCA tranformation and a decision tree classifier. The pipeline is trained on imbalanced binary-class data and evaluated on a hold-out set. The user applies the process in a simple way while the internal details of the calculations are hidden.</p>
<div id="d5b3e8ae" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import classes and functions.</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn_extra.gsmote <span class="im">import</span> GeometricSMOTE </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate an imbalanced binary-class dataset.</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  random_state<span class="op">=</span><span class="dv">23</span>,</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  n_classes<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  n_samples<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>  weights<span class="op">=</span>[<span class="fl">0.8</span>, <span class="fl">0.2</span>],</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data to training and hold-out sets.</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the pipeline's objects with default hyperparameters.</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>gsmote <span class="op">=</span> GeometricSMOTE(random_state<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA()</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the pipeline.</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>pip <span class="op">=</span> make_pipeline(gsmote, pca, clf)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the pipeline to the training set.</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>pip.fit(X_train, y_train)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the pipeline on the hold-out set using the F-score.</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>test_score <span class="op">=</span> f1_score(y_test, pip.predict(X_test))</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'F-score on hold-out set: </span><span class="sc">{</span>test_score<span class="sc">}</span><span class="ss">.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>F-score on hold-out set: 0.7.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/gdouzas/Library/Application Support/pdm/venvs/blog-h-aHQONM-3.11/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.
  warnings.warn(</code></pre>
</div>
</div>
</section>
</section>
<section id="clustering-based-oversampling-3" class="level2">
<h2 class="anchored" data-anchor-id="clustering-based-oversampling-3">Clustering-based oversampling</h2>
<section id="basic-example-1" class="level3">
<h3 class="anchored" data-anchor-id="basic-example-1">Basic example</h3>
<p>An example of resampling an imbalanced dataset using the <code>fit_resample</code> method is presented. Initially, a binary-class imbalanced dataset is generated. Next, <code>KMeansSMOTE</code> oversampler is initialized with the default parameters. This corresponds to the KMeans-SMOTE algorithm as presented in <span class="citation" data-cites="douzas_improving_2018">(<a href="#ref-douzas_improving_2018" role="doc-biblioref">Douzas, Bacao, and Last 2018</a>)</span>. Finally, the oversampler’s <code>fit_resample</code> method is used to resample the data. Printing the class distribution before and after resampling confirms that the resampled data <code>X_res</code>, <code>y_res</code> are perfectly balanced. <code>X_res</code>, <code>y_res</code> can be used as training data for any classifier in the place of <code>X</code>, <code>y</code>.</p>
<div id="3fb4faf7" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import classes and functions.</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn_extra.clover.over_sampling <span class="im">import</span> KMeansSMOTE</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate an imbalanced binary class dataset.</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">23</span>, </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    n_classes<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    n_features<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    n_samples<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    weights<span class="op">=</span>[<span class="fl">0.8</span>, <span class="fl">0.2</span>]</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create KMeans-SMOTE object with default hyperparameters.</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>kmeans_smote <span class="op">=</span> KMeansSMOTE(random_state<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Resample the imbalanced dataset.</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>X_res, y_res <span class="op">=</span> kmeans_smote.fit_resample(X, y) </span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Print number of samples per class for initial and resampled data. </span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>init_count <span class="op">=</span> <span class="bu">list</span>(Counter(y).values())</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>resampled_count <span class="op">=</span> <span class="bu">list</span>(Counter(y_res).values())</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Initial class distribution: </span><span class="sc">{</span>init_count<span class="sc">}</span><span class="ss">.'</span>) </span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Resampled class distribution: </span><span class="sc">{</span>resampled_count<span class="sc">}</span><span class="ss">.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Initial class distribution: [792, 208].
Resampled class distribution: [792, 792].</code></pre>
</div>
</div>
</section>
<section id="machine-learning-pipeline-1" class="level3">
<h3 class="anchored" data-anchor-id="machine-learning-pipeline-1">Machine learning pipeline</h3>
<p>As mentioned before, any clustering-based oversampler can be used as a part of a machine learning pipeline. A a pipeline is presented, composed by the combination of Borderline SMOTE oversampler and hierarchical clustering, a PCA tranformation and a decision tree classifier. The pipeline is trained on multi-class imbalanced data and evaluated on a hold-out set. The user applies the process in a simple way while the internal details of the calculations are hidden.</p>
<div id="0d20a8d0" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import classes and functions.</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn_extra.clover.over_sampling <span class="im">import</span> ClusterOverSampler</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> AgglomerativeClustering</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> BorderlineSMOTE</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate an imbalanced multi-class dataset.</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">23</span>, </span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    n_classes<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    n_informative<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    n_samples<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    weights<span class="op">=</span>[<span class="fl">0.8</span>, <span class="fl">0.1</span>, <span class="fl">0.1</span>]</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data to training and hold-out sets.</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, random_state<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the pipeline's objects with default hyperparameters.</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>hclusterer_bsmote <span class="op">=</span> ClusterOverSampler(oversampler<span class="op">=</span>BorderlineSMOTE(random_state<span class="op">=</span><span class="dv">5</span>), clusterer<span class="op">=</span>AgglomerativeClustering(), random_state<span class="op">=</span><span class="dv">19</span>)</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA()</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the pipeline.</span></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>pip <span class="op">=</span> make_pipeline(hclusterer_bsmote, pca, clf)</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the pipeline to the training set.</span></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>pip.fit(X_train, y_train)</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the pipeline on the hold-out set using the F-score.</span></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>test_score <span class="op">=</span> f1_score(y_test, pip.predict(X_test), average<span class="op">=</span><span class="st">'micro'</span>)</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'F-score on hold-out set: </span><span class="sc">{</span>test_score<span class="sc">:.2f}</span><span class="ss">.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>F-score on hold-out set: 0.75.</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="quality-control" class="level1">
<h1>Quality control</h1>
<p>All functions and classes have been tested for functionality and usability. These tests are integrated into the GitHub Actions continuous integration (CI) service and they are automatically run each time new commits are pushed to GitHub using all supported operating systems and Python versions. Checks in code quality, vulnerabilities in dependencies and type annotations are applied through external libraries. Various development scripts that automate the above tasks are provided and described in detail in the Contributing section of the online documentation and Github.</p>
</section>
<section id="availability" class="level1">
<h1>Availability</h1>
<section id="operating-system" class="level2">
<h2 class="anchored" data-anchor-id="operating-system">Operating system</h2>
<p>Any system (GNU/Linux, Mac OSX, Windows) capable of running Python ≥ 3.10.</p>
</section>
<section id="programming-language" class="level2">
<h2 class="anchored" data-anchor-id="programming-language">Programming language</h2>
<p>Python 3.10, or higher.</p>
<section id="dependencies" class="level3">
<h3 class="anchored" data-anchor-id="dependencies">Dependencies</h3>
<ul>
<li>scipy &gt;= 1.7.2</li>
<li>numpy &gt;= 1.22</li>
<li>imbalanced-learn &gt;= 0.13.0</li>
</ul>
</section>
<section id="list-of-contributors" class="level3">
<h3 class="anchored" data-anchor-id="list-of-contributors">List of contributors</h3>
<p>The software was created by Georgios Douzas.</p>
</section>
<section id="software-location" class="level3">
<h3 class="anchored" data-anchor-id="software-location">Software location</h3>
<section id="zenodo" class="level4">
<h4 class="anchored" data-anchor-id="zenodo">Zenodo</h4>
<ul>
<li><strong>Name:</strong> imbalanced-learn-extra</li>
<li><strong>Persistent identifier:</strong> https://doi.org/10.5281/zenodo.15561408</li>
<li><strong>Licence:</strong> MIT License</li>
<li><strong>Publisher:</strong> Zenodo</li>
<li><strong>Version published:</strong> 0.2.9</li>
<li><strong>Date published:</strong> 01/10/2021</li>
</ul>
</section>
<section id="github" class="level4">
<h4 class="anchored" data-anchor-id="github">GitHub</h4>
<ul>
<li><strong>Name:</strong> imbalanced-learn-extra</li>
<li><strong>Persistent identifier:</strong> https://github.com/georgedouzas/imbalanced-learn-extra</li>
<li><strong>Licence:</strong> MIT</li>
<li><strong>Date published:</strong> 01/10/2021</li>
</ul>
</section>
</section>
<section id="language" class="level3">
<h3 class="anchored" data-anchor-id="language">Language</h3>
<p>English</p>
</section>
</section>
</section>
<section id="reuse-potential" class="level1">
<h1>Reuse potential</h1>
<p>The <code>imbalanced-learn-extra</code> project provides the only Python implementation, to the best of our knowledge, that provides a generic way to construct any clustering-based oversampler. A significant advantage of this implementation is that it is built on top of the Scikit-Learn’s ecosystem and therefore it can be easily used in typical machine learning workflows. Also, the public API of any clustering-based oversampler is an extension of the one provided in Imbalanced-Learn. This means that users of Imbalanced-Learn and Scikit-Learn, that apply oversampling on imbalanced data, can integrate <code>imbalanced-learn-extra</code> in their existing work in a straightforward manner.</p>
<p>Users can request support by opening an issue on GitHub. Additionally users may do Pull Requests and contribute to the development of <code>imbalanced-learn-extra</code>. The documentation of the projects describes in detail the API and provides various complete examples.</p>
</section>
<section id="funding-statement" class="level1">
<h1>Funding statement</h1>
<p>Funding: This research was supported by a grant from the Portuguese Foundation for Science and Technology (“Fundação para a Ciência e a Tecnologia”), DSAIPA/DS/0116/2019.</p>
</section>
<section id="competing-interests" class="level1">
<h1>Competing interests</h1>
<p>The authors declare that they have no competing interests.</p>
</section>
<section id="references" class="level1">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-barua_mwmote_2014" class="csl-entry" role="listitem">
Barua, Sukarna, Md. Monirul Islam, Xin Yao, and Kazuyuki Murase. 2014. <span>“<span>MWMOTE</span>–<span>Majority</span> <span>Weighted</span> <span>Minority</span> <span>Oversampling</span> <span>Technique</span> for <span>Imbalanced</span> <span>Data</span> <span>Set</span> <span>Learning</span>.”</span> <em>IEEE Transactions on Knowledge and Data Engineering</em> 26 (2): 405–25. <a href="https://doi.org/10.1109/TKDE.2012.232">https://doi.org/10.1109/TKDE.2012.232</a>.
</div>
<div id="ref-chawla_smote_2002" class="csl-entry" role="listitem">
Chawla, N. V., K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. 2002. <span>“<span>SMOTE</span>: <span>Synthetic</span> <span>Minority</span> <span>Over</span>-Sampling <span>Technique</span>.”</span> <em>Journal of Artificial Intelligence Research</em> 16 (June): 321–57. <a href="https://doi.org/10.1613/jair.953">https://doi.org/10.1613/jair.953</a>.
</div>
<div id="ref-goos_smoteboost_2003" class="csl-entry" role="listitem">
Chawla, Nitesh V., Aleksandar Lazarevic, Lawrence O. Hall, and Kevin W. Bowyer. 2003. <span>“<span>SMOTEBoost</span>: <span>Improving</span> <span>Prediction</span> of the <span>Minority</span> <span>Class</span> in <span>Boosting</span>.”</span> In <em>Knowledge <span>Discovery</span> in <span>Databases</span>: <span>PKDD</span> 2003</em>, edited by Gerhard Goos, Juris Hartmanis, Jan van Leeuwen, Nada Lavrač, Dragan Gamberger, Ljupčo Todorovski, and Hendrik Blockeel, 2838:107–19. Berlin, Heidelberg: Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/978-3-540-39804-2_12">https://doi.org/10.1007/978-3-540-39804-2_12</a>.
</div>
<div id="ref-douzas_self-organizing_2017" class="csl-entry" role="listitem">
Douzas, Georgios, and Fernando Bacao. 2017. <span>“Self-<span>Organizing</span> <span>Map</span> <span>Oversampling</span> (<span>SOMO</span>) for Imbalanced Data Set Learning.”</span> <em>Expert Systems with Applications</em> 82 (October): 40–52. <a href="https://doi.org/10.1016/j.eswa.2017.03.073">https://doi.org/10.1016/j.eswa.2017.03.073</a>.
</div>
<div id="ref-douzas_geometric_2019" class="csl-entry" role="listitem">
———. 2019. <span>“Geometric <span>SMOTE</span> a Geometrically Enhanced Drop-in Replacement for <span>SMOTE</span>.”</span> <em>Information Sciences</em> 501 (October): 118–35. <a href="https://doi.org/10.1016/j.ins.2019.06.007">https://doi.org/10.1016/j.ins.2019.06.007</a>.
</div>
<div id="ref-douzas_improving_2018" class="csl-entry" role="listitem">
Douzas, Georgios, Fernando Bacao, and Felix Last. 2018. <span>“Improving Imbalanced Learning Through a Heuristic Oversampling Method Based on k-Means and <span>SMOTE</span>.”</span> <em>Information Sciences</em> 465 (October): 1–20. <a href="https://doi.org/10.1016/j.ins.2018.06.056">https://doi.org/10.1016/j.ins.2018.06.056</a>.
</div>
<div id="ref-douzas_gsomo_2021" class="csl-entry" role="listitem">
Douzas, Georgios, Rene Rauch, and Fernando Bacao. 2021. <span>“G-<span>SOMO</span>: <span>An</span> Oversampling Approach Based on Self-Organized Maps and Geometric <span>SMOTE</span>.”</span> <em>Expert Systems with Applications</em> 183 (November): 115230. <a href="https://doi.org/10.1016/j.eswa.2021.115230">https://doi.org/10.1016/j.eswa.2021.115230</a>.
</div>
<div id="ref-fernandez_analysing_2013" class="csl-entry" role="listitem">
Fernández, Alberto, Victoria López, Mikel Galar, María José Del Jesus, and Francisco Herrera. 2013. <span>“Analysing the Classification of Imbalanced Data-Sets with Multiple Classes: <span>Binarization</span> Techniques and Ad-Hoc Approaches.”</span> <em>Knowledge-Based Systems</em> 42 (April): 97–110. <a href="https://doi.org/10.1016/j.knosys.2013.01.018">https://doi.org/10.1016/j.knosys.2013.01.018</a>.
</div>
<div id="ref-haibo_he_learning_2009" class="csl-entry" role="listitem">
Haibo He, and E. A. Garcia. 2009. <span>“Learning from <span>Imbalanced</span> <span>Data</span>.”</span> <em>IEEE Transactions on Knowledge and Data Engineering</em> 21 (9): 1263–84. <a href="https://doi.org/10.1109/TKDE.2008.239">https://doi.org/10.1109/TKDE.2008.239</a>.
</div>
<div id="ref-haixiang_learning_2017" class="csl-entry" role="listitem">
Haixiang, Guo, Li Yijing, Jennifer Shang, Gu Mingyun, Huang Yuanyue, and Gong Bing. 2017. <span>“Learning from Class-Imbalanced Data: <span>Review</span> of Methods and Applications.”</span> <em>Expert Systems with Applications</em> 73 (May): 220–39. <a href="https://doi.org/10.1016/j.eswa.2016.12.035">https://doi.org/10.1016/j.eswa.2016.12.035</a>.
</div>
<div id="ref-lemaitre_imbalanced-learn_2016" class="csl-entry" role="listitem">
Lemaitre, Guillaume, Fernando Nogueira, and Christos K. Aridas. 2016. <span>“Imbalanced-Learn: <span>A</span> <span>Python</span> <span>Toolbox</span> to <span>Tackle</span> the <span>Curse</span> of <span>Imbalanced</span> <span>Datasets</span> in <span>Machine</span> <span>Learning</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.1609.06570">https://doi.org/10.48550/ARXIV.1609.06570</a>.
</div>
<div id="ref-pedregosa_scikit-learn_2012" class="csl-entry" role="listitem">
Pedregosa, Fabian, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, et al. 2012. <span>“Scikit-Learn: <span>Machine</span> <span>Learning</span> in <span>Python</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.1201.0490">https://doi.org/10.48550/ARXIV.1201.0490</a>.
</div>
<div id="ref-hutchison_learning_2004" class="csl-entry" role="listitem">
Prati, Ronaldo C., Gustavo E. A. P. A. Batista, and Maria Carolina Monard. 2004. <span>“Learning with <span>Class</span> <span>Skews</span> and <span>Small</span> <span>Disjuncts</span>.”</span> In <em>Advances in <span>Artificial</span> <span>Intelligence</span> – <span>SBIA</span> 2004</em>, edited by David Hutchison, Takeo Kanade, Josef Kittler, Jon M. Kleinberg, Friedemann Mattern, John C. Mitchell, Moni Naor, et al., 3171:296–306. Berlin, Heidelberg: Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/978-3-540-28645-5_30">https://doi.org/10.1007/978-3-540-28645-5_30</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>