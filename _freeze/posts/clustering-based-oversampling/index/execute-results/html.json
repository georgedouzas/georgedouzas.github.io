{
  "hash": "165134c4f4c0d7cd43a094c8cf47cf97",
  "result": {
    "markdown": "---\ntitle: Clustering-based oversampling\ndescription: Combining clustering and oversampling to increase classification performance.\nauthor: Georgios Douzas\ndate: '2022-05-02'\ncategories:\n  - Project\n  - Imbalanced Learning\nimage: featured.png\n---\n\n![Clustering-based oversampling](featured.png)\n\n## Introduction\n\nSMOTE algorithm and its variants generate synthetic samples along line segments that join minority class instances. SMOTE\naddresses only the between-classes imbalance. On the other hand, SMOTE does nothing about areas of the input space that differ\nsignificantly in the density of a particular class, an issue known as within-classes imbalance.\n\nA straightforward approach is to combine oversamplers with clustering algorithms.\n[SOMO](https://www.sciencedirect.com/science/article/abs/pii/S0957417417302324) and\n[KMeans-SMOTE](https://www.sciencedirect.com/science/article/abs/pii/S0020025518304997) algorithms are specific realizations of\nthis approach that have been shown to outperform other standard oversamplers in a large number of datasets.\n\n## Implementation\n\nI have developed a Python implementation of the above clustering-based oversampling approach called\n[cluster-over-sampling](https://github.com/georgedouzas/cluster-over-sampling), which integrates seamlessly with the\n[Scikit-Learn](https://scikit-learn.org/stable/) and [Imbalanced-Learn](https://imbalanced-learn.org/stable/) ecosystems. You can\ncheck the [documentation](https://github.com/georgedouzas/cluster-over-sampling) for more details on installation and the API.\n\n## Functionality\n\nLet's first generate a binary class imbalanced dataset, represented by the input matrix `X` and the target vector `y`. Using a\nhigh value for the `flip_y` parameter, we ensure that the data are noisy thus the clustering of the input space will help the\noversampling process:\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# Imports\nfrom sklearn.datasets import make_classification\n\n# Set random seed\nrnd_seed = 4\n\n# Generate imbalanced data\nX, y = make_classification(\n  n_samples=500,\n  n_classes=2,\n  weights=[0.9, 0.1],\n  random_state=rnd_seed,\n  n_informative=3,\n  class_sep=1.0,\n  n_features=10,\n  flip_y=0.3\n)\n```\n:::\n\n\nThe function `print_characteristics` extracts and prints the main characteristics of a binary class dataset. Specifically, it\nprints the number of samples, the number of features, the labels, and the number of samples for the majority and minority classes\nas well as the Imbalance Ratio, defined as the ratio between the number of instances of the majority and minority classes.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Imports\nfrom collections import Counter\n\n# Define function to print dataset's characteristics\ndef print_characteristics(X, y):\n  n_samples, n_features = X.shape\n  count_y = Counter(y)\n  (maj_label, n_samples_maj), (min_label, n_samples_min) = count_y.most_common()\n  ir = n_samples_maj / n_samples_min\n  print(\n    f'Number of samples: {n_samples}',\n    f'Number of features: {n_features}',\n    f'Majority class label: {maj_label}',\n    f'Number of majority class samples: {n_samples_maj}',\n    f'Minority class label: {min_label}',\n    f'Number of minority class samples: {n_samples_min}',\n    f'Imbalance Ratio: {ir:.1f}',\n    sep='\\n'\n  )\n```\n:::\n\n\nI use the above function to print the main characteristics of the generated imbalanced dataset:\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nprint_characteristics(X, y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of samples: 500\nNumber of features: 10\nMajority class label: 0\nNumber of majority class samples: 379\nMinority class label: 1\nNumber of minority class samples: 121\nImbalance Ratio: 3.1\n```\n:::\n:::\n\n\nI will combine the `SMOTE` oversampler and the `KMeans` clusterer to rebalance the above dataset. The combined\nclusterer-oversampler can be constructed by importing the `SMOTE` oversampler from Imbalanced-Learn, `KMeans` from Scikit-Learn,\nand `ClusterOverSampler` from `cluster-over-sampling`. Then following the Imbalanced Learn API, we can use the `fit_resample`\nmethod to resample the imbalanced dataset:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Imports\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.cluster import KMeans\nfrom clover.over_sampling import ClusterOverSampler\n\n# Create KMeans-SMOTE instance\nsmote = SMOTE(random_state=rnd_seed + 1)\nkmeans = KMeans(n_clusters=10, random_state=rnd_seed + 3, n_init=50)\nkmeans_smote = ClusterOverSampler(oversampler=smote, clusterer=kmeans)\n\n# Fit and resample imbalanced data\nX_res, y_res = kmeans_smote.fit_resample(X, y)\n```\n:::\n\n\nAgain we can print the main characteristics of the rebalanced dataset:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nprint_characteristics(X_res, y_res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of samples: 759\nNumber of features: 10\nMajority class label: 1\nNumber of majority class samples: 380\nMinority class label: 0\nNumber of minority class samples: 379\nImbalance Ratio: 1.0\n```\n:::\n:::\n\n\nThe default behavior is to generate the appropriate number of minority class samples so that the resampled dataset is perfectly\nbalanced (although this sometimes may result in an approximately balanced dataset). Also, cluster-over-sampling provides for\nconvenience, the clustering-based oversamplers [SOMO](https://www.sciencedirect.com/science/article/abs/pii/S0957417417302324) and\n[KMeans-SMOTE](https://www.sciencedirect.com/science/article/abs/pii/S0020025518304997), as well as\n[G-SOMO](https://www.sciencedirect.com/science/article/abs/pii/S095741742100662X) that uses [Geometric\nSMOTE](../../publication/gsmote_journal) as the oversampler in place of SMOTE.\n\nAs mentioned above, training a classifier on imbalanced data may result in suboptimal performance on out-of-sample data. The\nfunction `calculate_cv_scores` calculates the average 5-fold cross-validation F and accuracy scores across 5 runs\nof a `RandomForestClassifier` that is optionally combined with an oversampler through a pipeline:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Imports\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_validate, StratifiedKFold\nfrom sklearn.metrics import make_scorer, accuracy_score, f1_score\nfrom imblearn.pipeline import make_pipeline\n\n# Define function that calculates out-of-sample scores\ndef calculate_cv_scores(oversampler, X, y):\n  cv_scores = []\n  scorers = {'f_score': make_scorer(f1_score), 'accuracy': make_scorer(accuracy_score)}\n  n_runs = 5\n  for ind in range(n_runs):\n    rnd_seed = 8 * ind\n    classifier = RandomForestClassifier(random_state=rnd_seed)\n    if oversampler is not None:\n      classifier = make_pipeline(\n        oversampler.set_params(random_state=rnd_seed + 5),\n        classifier\n      )\n    scores = cross_validate(\n      estimator=classifier,\n      X=X,\n      y=y,\n      scoring=scorers,\n      cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=rnd_seed + 6)\n    )\n    cv_scores.append([scores[f'test_{scorer}'].mean() for scorer in scorers])\n  return np.mean(cv_scores, axis=0)\n```\n:::\n\n\nUsing the above function, we can calculate the out-of-sample performance when no oversampling is applied, as well as when SMOTE\nand DBSCAN-SMOTE are used as oversamplers:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# Imports\nfrom sklearn.cluster import DBSCAN\nfrom clover.over_sampling import ClusterOverSampler\n\n# Calculate cross-validation scores\nmapping = {'No oversampling': None, 'SMOTE': SMOTE(), 'DBSCAN-SMOTE': ClusterOverSampler(oversampler=SMOTE(), clusterer=DBSCAN())}\ncv_scores = {}\nfor name, oversampler in mapping.items():\n  cv_scores[name] = calculate_cv_scores(oversampler, X, y)\ncv_scores = pd.DataFrame(cv_scores, index = ['F-score', 'Accuracy'])\ncv_scores\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No oversampling</th>\n      <th>SMOTE</th>\n      <th>DBSCAN-SMOTE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>F-score</th>\n      <td>0.250849</td>\n      <td>0.349954</td>\n      <td>0.365352</td>\n    </tr>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.773200</td>\n      <td>0.715600</td>\n      <td>0.723600</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNotice that using accuracy as an evaluation metric is not a good choice when the data is imbalanced. For example, a\ntrivial classifier that always predicts the majority class would still have an accuracy equal to 0.90, even though all the\nminority class instances are misclassified. On the other hand, the F-score is an appropriate evaluation metric for\nimbalanced data since it considers the accuracies per class.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}